This workflow describes each major step of the face recognition pipeline using Facenet-PyTorch, including data handling, feature extraction, matching, and evaluation.

---

1. **Setup & Dependencies**
- **Install required packages:**  
  `facenet-pytorch`, `torch`, `torchvision`, `pillow`, `numpy`, `matplotlib`, `scikit-learn`, `seaborn`, `tqdm`
- **Import libraries.**
- **Set device:**  
  Use GPU if available; fallback to CPU.

2. **Data and Model Preparation**
- **Define directory structure:**  
  - `train_dir` (for registration, if needed)  
  - `val_dir` (validation/test set, including "distortion" folders)
- **Load pretrained models:**  
  - `InceptionResnetV1` (FaceNet, for embeddings)  
  - `MTCNN` (for face detection and alignment)

3. **Embedding Extraction with TTA**
- **Test-Time Augmentation (TTA):**  
  For each image, generate multiple augmented versions (brightness, sharpness, contrast, original).
- **Face detection & alignment:**  
  Apply MTCNN to each augmented image.
- **Get embeddings:**  
  Pass detected faces through FaceNet and average the results to obtain a robust embedding.

4. **Build Validation Feature Database**
- **Iterate over each person in `val_dir`:**  
  - For each clean (non-distorted) image:
    - Extract embedding (using TTA).
    - Store embeddings in a dictionary:  
      `{person_name: [embedding1, embedding2, ...]}`
      
5. **Distorted Image Matching**
- **Iterate over each personâ€™s "distortion" folder in `val_dir`:**  
  - For each distorted image:
    - Extract embedding.
    - Compute cosine similarity with every stored embedding in the validation feature DB.
    - Identify the most similar person (highest similarity score).

6. **Thresholding and Result Storage**
- **Apply similarity threshold:**  
  Only accept a match if the score exceeds a set threshold (e.g., 0.65).
- **Store results:**  
  Save file name, true label, predicted label, similarity score, and match indicator.

7. **Evaluation and Analysis**
- **Print sample results.**
- **Compute metrics:**  
  - Top-1 Accuracy  
  - Macro-averaged F1 Score
- **Threshold tuning:**  
  Plot accuracy and F1 as functions of the similarity threshold.
- **Cosine similarity histogram:**  
  Visualize the distribution of similarity scores for matches and mismatches.

8. **Visualization**
- **Threshold tuning curve:**  
  Shows how accuracy and F1 score vary with threshold.
- **Histogram of similarity scores:**  
  Compare genuine vs imposter match distributions.

9. **End**

